<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">

<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #1E92FB; /*进度条颜色*/
        height: 3px;
    }
    .pace .pace-progress-inner {
         box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>

<script>/*文章访问输入密码*/
    (function(){
        if(''){
            if (prompt('请输入文章密码') !== ''){
                alert('密码错误！');
                history.back();
            }
        }
    })();
</script>


  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-fill-left.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/stupid-180.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/stupid-32.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/stupid-16.png?v=5.1.4">


  <link rel="mask-icon" href="/images/stupid.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="树模型,XGB," />





  <link rel="alternate" href="/atom.xml" title="Fall Out Boy" type="application/atom+xml" />






<meta name="description" content="0. Decision Tree-决策树启发式算法 分类树：处理分类问题。回归树：预测数值。 场景：用二十个问题猜出提问者脑中想好的一个事物。不断缩小范围。 决策树是一种弱分类器，简单易懂，相比复杂完善的方法，通过ensemble来组合弱分类器的方式更不容易过拟合。 原理概念熵：体系混乱的程度。信息熵（香农熵）：信息度量方式，信息越有序越低，否则反之。信息增益：划分数据集前后信息发生的变化。Gin">
<meta name="keywords" content="树模型,XGB">
<meta property="og:type" content="article">
<meta property="og:title" content="树形模型&amp;XGBoost">
<meta property="og:url" content="blog.lovelaolao.xin/机器学习/树形模型&XGBoost/index.html">
<meta property="og:site_name" content="Fall Out Boy">
<meta property="og:description" content="0. Decision Tree-决策树启发式算法 分类树：处理分类问题。回归树：预测数值。 场景：用二十个问题猜出提问者脑中想好的一个事物。不断缩小范围。 决策树是一种弱分类器，简单易懂，相比复杂完善的方法，通过ensemble来组合弱分类器的方式更不容易过拟合。 原理概念熵：体系混乱的程度。信息熵（香农熵）：信息度量方式，信息越有序越低，否则反之。信息增益：划分数据集前后信息发生的变化。Gin">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="blog.lovelaolao.xin/机器学习/树形模型&XGBoost/各种熵.png">
<meta property="og:image" content="blog.lovelaolao.xin/机器学习/树形模型&XGBoost/AdaBoost.jpeg">
<meta property="og:image" content="blog.lovelaolao.xin/机器学习/树形模型&XGBoost/GBDT损失函数.png">
<meta property="og:image" content="blog.lovelaolao.xin/机器学习/树形模型&XGBoost/GBDT算法流程.png">
<meta property="og:image" content="blog.lovelaolao.xin/机器学习/树形模型&XGBoost/DBDT优化目标及负梯度理论.jpeg">
<meta property="og:image" content="blog.lovelaolao.xin/机器学习/树形模型&XGBoost/贪婪算法.png">
<meta property="og:image" content="blog.lovelaolao.xin/机器学习/树形模型&XGBoost/近似算法.png">
<meta property="og:image" content="blog.lovelaolao.xin/机器学习/树形模型&XGBoost/xgb目标函数.png">
<meta property="og:image" content="blog.lovelaolao.xin/机器学习/树形模型&XGBoost/xgb目标函数正则项.png">
<meta property="og:updated_time" content="2018-08-19T14:45:57.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="树形模型&amp;XGBoost">
<meta name="twitter:description" content="0. Decision Tree-决策树启发式算法 分类树：处理分类问题。回归树：预测数值。 场景：用二十个问题猜出提问者脑中想好的一个事物。不断缩小范围。 决策树是一种弱分类器，简单易懂，相比复杂完善的方法，通过ensemble来组合弱分类器的方式更不容易过拟合。 原理概念熵：体系混乱的程度。信息熵（香农熵）：信息度量方式，信息越有序越低，否则反之。信息增益：划分数据集前后信息发生的变化。Gin">
<meta name="twitter:image" content="blog.lovelaolao.xin/机器学习/树形模型&XGBoost/各种熵.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: 'EQNFCFWZVQ',
      apiKey: '19713fffa872ec9f90f6a8ade436f7e5',
      indexName: 'HZBlog',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="blog.lovelaolao.xin/机器学习/树形模型&XGBoost/"/>





  <title>树形模型&XGBoost | Fall Out Boy</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?40b71fb0e7bcadbfd695ea89064f5aa9";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Fall Out Boy</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="blog.lovelaolao.xin/机器学习/树形模型&XGBoost/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hou Zhe">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/handsomeme.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Fall Out Boy">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">树形模型&XGBoost</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-03-01T22:16:00+08:00">
                2018-03-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/机器学习/树形模型&XGBoost/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count gitment-comments-count" data-xid="/机器学习/树形模型&XGBoost/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/机器学习/树形模型&XGBoost/" class="leancloud_visitors" data-flag-title="树形模型&XGBoost">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  6,177 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  22 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="0-Decision-Tree-决策树"><a href="#0-Decision-Tree-决策树" class="headerlink" title="0. Decision Tree-决策树"></a>0. Decision Tree-决策树</h1><p>启发式算法</p>
<p>分类树：处理分类问题。<br>回归树：预测数值。</p>
<p>场景：用二十个问题猜出提问者脑中想好的一个事物。不断缩小范围。</p>
<p>决策树是一种弱分类器，简单易懂，相比复杂完善的方法，通过ensemble来组合弱分类器的方式更不容易过拟合。</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p><img src="./各种熵.png" alt="avatar"><br><strong>熵</strong>：体系混乱的程度。<br><strong>信息熵（香农熵）</strong>：信息度量方式，信息越有序越低，否则反之。<br><strong>信息增益</strong>：划分数据集前后信息发生的变化。<br><strong>Gini指数</strong>：反映了在数据集中随机抽取两个样本，类别不同的概率。越低代表纯度越高。</p>
<h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><ol>
<li>检测所有数据分类标签是否相同。</li>
<li>穷举每一个特征的每一个阈值，选择划分数据集的最好特征。（即划分之后信息熵最小，也即两个分类比例最远离1:1，信息增益最大的特征，相当于每次划分选一个特征出来，考虑所有特征，选划分之后信息熵最小-也就是信息增益（之前减之后）最大的那个，每次划分之后取出满足划分的数据集做之后的数据集）</li>
<li>划分数据集</li>
<li>创建分支节点</li>
<li>循环2</li>
<li>返回分支节点</li>
</ol>
<p>分类树（C4.5分类树）在划分数据的时候，会穷举特征每一个阈值，找到熵最小的那个。</p>
<h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h3><p>收集数据<br>准备数据（需要离散化的数据）<br>分析数据（计算信息熵的公式、按照特征划分数据集方法、选择最好的数据划分方式方法）<br>训练算法（创建决策树）<br>测试算法（使用决策树执行分类）<br>使用算法（可以获得树的结构）  </p>
<h3 id="树的纯度"><a href="#树的纯度" class="headerlink" title="树的纯度"></a>树的纯度</h3><p><strong>纯度差 = 信息增益</strong><br>一个分割点两侧的类别里，各自的同类样本的多少。（也可以理解为信息增益的其他角度理解）</p>
<p>纯度量化指标：（越小纯度越高）</p>
<ul>
<li>Gini不纯度</li>
<li>熵（Entropy）</li>
<li>错误率</li>
</ul>
<h2 id="构建决策树的方法比较"><a href="#构建决策树的方法比较" class="headerlink" title="构建决策树的方法比较"></a>构建决策树的方法比较</h2><table>
<thead>
<tr>
<th style="text-align:left">模型</th>
<th style="text-align:center">特点</th>
<th style="text-align:center">过程</th>
<th style="text-align:center">缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">ID3</td>
<td style="text-align:center">在决策树各个子节点上应用<strong>信息增益</strong>准则选择特征，递归的构建决策树。</td>
<td style="text-align:center">从根节点开始，对节点计算所有可能的特征的信息增益，选择信息增益最大的特征（先筛选特征而不是穷举所有特征的可能值）作为节点的特征（然后把该特征的所有可能取值都做划分方向，各个方向选择数据子集最大的作为本节点 特征+属性值 ）；再对子节点递归调用以上方法，构建决策树。直到所有特征的信息增益均很小或没有特征可以选择为止。最后得到一个决策树。</td>
<td style="text-align:center">用信息增益选择属性<strong>时偏向于选择分枝比较多的属性值</strong>，即取值多的属性（因为每个可能属性可能带来比较大的分类效果及信息增益，比如id）。<strong>不能处理连续属性</strong>。<strong>不能处理属性具有缺失值的样本</strong>。<strong>容易决策树很深，过拟合</strong>。</td>
</tr>
<tr>
<td style="text-align:left">C4.5</td>
<td style="text-align:center">对ID3算法的改进，（悲观剪枝法）</td>
<td style="text-align:center">用<strong>信息增益率比</strong>来选择属性（具体流程完全和ID3一样只是判别标准不一样，这样对多取值特征没那么敏感了，会排除增益高且信息量也高的，如id这个特征），在决策树的构造过程中对树<strong>进行剪枝处理过拟合</strong>，<strong>对非离散数据也能处理</strong>（排序去重后用每个样本可能值做阈值转换成离散数据处理方式），<strong>能够对不完整数据进行处理</strong></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:left">CART</td>
<td style="text-align:center">可用于<strong>回归、分类</strong>。<strong>二元切分法</strong>。<strong>（后剪枝）通过交叉验证递归地修剪决策树</strong>，减去使损失下降不够大的结点。从而使训练误差和测试误差达到一个很好地平衡点。支持离散、连续数据。</td>
<td style="text-align:center"><strong>分类树</strong>：<strong>gini指数–纯度</strong>，生成树的时候计算数据集所有特征的所有可能类别的gini指数，找最小gini指数的特征及可能值作为“是”、“否”的切分点。<strong>回归树</strong>：<strong>最小平方差</strong>（启发式分割，选取所有样本的取值做分割点）生成树的时候尝试所有样本的所有特征下的取值作为切分点将数据集一分为二，将两类数据子集的平方误差和作为判定标准，找最小平方误差和的样本特征j及切分点s。</td>
</tr>
</tbody>
</table>
<h3 id="为什么多取值属性会包含更多的熵"><a href="#为什么多取值属性会包含更多的熵" class="headerlink" title="为什么多取值属性会包含更多的熵"></a>为什么多取值属性会包含更多的熵</h3><p>因为属性取值越多就代表分类越多，什么样的数据熵比较低，当然是有序的，也就是尽量全是同类属性的数据，那么取值越多分类越多所包含的熵就越多，从熵的计算形式上也可以总结出这一结论。</p>
<h1 id="1-随机森林-Radam-Forest-与-AdaBoost"><a href="#1-随机森林-Radam-Forest-与-AdaBoost" class="headerlink" title="1. 随机森林-Radam Forest 与 AdaBoost"></a>1. 随机森林-Radam Forest 与 AdaBoost</h1><p>这里用到了<strong>集成方法ensemble method</strong>。<br>树太多也会拟合。</p>
<h2 id="随机森林-bagging"><a href="#随机森林-bagging" class="headerlink" title="随机森林-bagging"></a>随机森林-bagging</h2><h3 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h3><p>借助<strong>数据随机化+特征选择随机化</strong>来构建不同的决策树，提升系统的多样性。<br>注意每个决策树的数据集是有放回的抽样（比无放回的准确率更高），这样一个决策树中可能有相同的数据。（<strong>过抽样</strong>，此外还有<strong>欠抽样</strong>删除部分样本）  不做剪枝尽情生长。</p>
<p><strong>注意：特征的随机化，不是每个决策树随机选择了部分特征，而是决策树的每个结点在分裂的时候，随机选择m（m&lt;&lt;M）的属性来做分裂候选</strong></p>
<h3 id="影响RF效果的参数"><a href="#影响RF效果的参数" class="headerlink" title="影响RF效果的参数"></a>影响RF效果的参数</h3><p>随机森林分类效果（错误率）与两个因素有关：<br>（1）森林中任意两棵树的相关性：相关性越大，错误率越大；<br>（2）森林中每棵树的分类能力：每棵树的分类能力越强，整个森林的错误率越低。<br>  减小特征选择个数m，树的相关性和分类能力也会相应的降低；增大m，两者也会随之增大。所以关键问题是如何选择最优的m（或者是范围），这也是随机森林唯一的一个参数。</p>
<h3 id="流程-1"><a href="#流程-1" class="headerlink" title="流程"></a>流程</h3><p>构建时加入了数据随机化+特征选择随机化。</p>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">优点：几乎不需要输入准备、可以隐式特征选择、训练速度非常快、下限很高、很多优秀开源的实现。  </span><br><span class="line">	能够处理高维度、离散、连续的数据。</span><br><span class="line">	可以生成一个proximite矩阵，度量样本之间的相似度。（样本落在相同叶子次数/总的树数）</span><br><span class="line">	容易并行化处理</span><br><span class="line">缺点：模型大小，是个很难解释的黑盒子。</span><br></pre></td></tr></table></figure>
<h2 id="AdaBoost-boosting"><a href="#AdaBoost-boosting" class="headerlink" title="AdaBoost-boosting"></a>AdaBoost-boosting</h2><h3 id="原理-2"><a href="#原理-2" class="headerlink" title="原理"></a>原理</h3><p>包括<strong>样本的权值D和分类器的权值alpha</strong>。<br>提高每个分类器的分错样本的权值。减小投错票的分类器的权重。<br>过程是根据<strong>公式</strong>自发调节的。<br>代价函数使用true positive、fp、fn、tn来综合评估的。<br><strong>前向/加法模型，加法分步算法。</strong></p>
<p><strong>损失函数：指数损失函数</strong><br>e的次幂。为什么：adaboost的迭代目的是寻找最小化loss的参数α、G，他是前向分步加法算法的特例，是一个加和模型，损失函数就是指数函数。</p>
<p>N个样本，M维特征：<br><strong>时间复杂度</strong>：排序O(M*N*logN）+ 每次迭代O(M*N)。<br><strong>空间复杂度</strong>：O(M*N)。<br>具体需要的消耗，还要考察迭代步伐等。</p>
<h3 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">优点：泛化错误率低。  </span><br><span class="line">	对弱分类器的要求很低，比随机好一点就行，（比随机差的，反过来用其实也是可以用的。）</span><br><span class="line">缺点：对异常点敏感。</span><br><span class="line">	数据不平衡导致分类精度下降。</span><br></pre></td></tr></table></figure>
<h3 id="公式推导"><a href="#公式推导" class="headerlink" title="公式推导"></a>公式推导</h3><p><img src="AdaBoost.jpeg" alt="avatar"></p>
<h1 id="2-回归树"><a href="#2-回归树" class="headerlink" title="2. 回归树"></a>2. 回归树</h1><p>CART（Classification and Regression Trees，分类回归树），既可以分类也可以回归。<br>将数据不断切分成易建模的块，分别建模线性回归。</p>
<h3 id="原理-3"><a href="#原理-3" class="headerlink" title="原理"></a>原理</h3><p>用总方差来衡量数据的混乱程度。<br>以前采用ID3来切分数据。将数据按某种特征所有取值每个取值各自一份。（还有一种是按照一个拟定标准，不足和超过的分成两份）。再将连续型数据离散化。<br>CART使用二元切分，修改信息熵用总方差来度量集合无组织程度，来用数结构处理回归问题。  </p>
<p><strong>决策树如何做回归：</strong><br>将每个节点通过阈值区分出的两个数据组，取平均值求loss。</p>
<h3 id="流程-2"><a href="#流程-2" class="headerlink" title="流程"></a>流程</h3><p>数据需要都是连续型，离散型数据需要映射为二值型。<br>不断切分到不能再切分，指定为叶节点。叶节点的值大小代表训练数据当前类的标签均值。</p>
<h3 id="特点-2"><a href="#特点-2" class="headerlink" title="特点"></a>特点</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">优点：可以对复杂的非线性数据建模。  </span><br><span class="line">缺点：结果很难理解。</span><br></pre></td></tr></table></figure>
<h2 id="树剪枝-pruning"><a href="#树剪枝-pruning" class="headerlink" title="树剪枝-pruning"></a>树剪枝-pruning</h2><p>一棵树的节点过多，容易过拟合。剪枝可以剪叶结点，也可以剪子树。</p>
<h3 id="预剪枝-prepruning"><a href="#预剪枝-prepruning" class="headerlink" title="预剪枝-prepruning"></a>预剪枝-prepruning</h3><p>提前停止树的增长。设定一二熵的停止阈值。节省了时间开销。<br>先验实际效果不好。原理是贪心的，所以可能带来欠拟合。</p>
<h3 id="后剪枝-postpruning"><a href="#后剪枝-postpruning" class="headerlink" title="后剪枝-postpruning"></a>后剪枝-postpruning</h3><p>决策树构造完成后，对拥有同样父节点的节点进行检查，判断合并后熵的增加是否小于一个阈值，那么就合并（塌陷处理）。目前是普遍做法。<br>一般会比预剪枝保留更多的分支，不容易出现欠拟合，但是需要自底向上检查，有很大的时间开销。<br>判断误差是在测试数据上判断的。</p>
<h2 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h2><p>定义：缺失值是指某个样本中某个属性取值的缺失，不是样本失衡、样本丢失的意思，是指样本中缺少了一个、多个值。 </p>
<p>常见处理方法：</p>
<ul>
<li>插值法（Imputation）： QUEST, CRUISE</li>
<li>替代法（Alternate/Surrogate Splits）：CART， CRUISE</li>
<li>缺失值单独分支（Missing value branch）：CHAID， GUIDE</li>
<li>概率权重（Probability weights）： C4.5</li>
</ul>
<p>总的来说有两个问题：  </p>
<table>
<thead>
<tr>
<th style="text-align:left">模型</th>
<th style="text-align:center">当存在属性值缺失，如何划分属性</th>
<th style="text-align:center">已知属性划分，缺失属性值的样本如何划分</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">ID3</td>
<td style="text-align:center">不计入该属性样本集中缺失属性值的样本训练，按剩下样本比例乘以信息增益。（相当于逃避不处理）</td>
<td style="text-align:center">逃避</td>
</tr>
<tr>
<td style="text-align:left">C4.5</td>
<td style="text-align:center">缺失属性值的样本进入所有可能分类分支，给所有样本加一个权重，（缺失属性值样本的权重变成各个分支中样本比例。）</td>
<td style="text-align:center">以不同的权重比例进入所有可能分支。（其实就是给之后统计结果加入权重概念）</td>
</tr>
<tr>
<td style="text-align:left">xgb</td>
<td style="text-align:center">训练的时候，将所有缺失属性值的数据全都导向到所有划分方向，假设他们属于所有属性值。然后比对各个方向哪个结果是最优的。</td>
<td style="text-align:center">选择训练时缺失属性值的数据进入的分支结果最优的分支划分。</td>
</tr>
</tbody>
</table>
<h2 id="多变量决策树"><a href="#多变量决策树" class="headerlink" title="多变量决策树"></a>多变量决策树</h2><p>就是每一个划分节点中不止包含一个属性划分，还有其他属性划分结合在一起。<br>这样在样本空间的决策边界就不再是平行于坐标轴（属性），而是“斜”的决策边界了。<br>常用算法：OCI。</p>
<h2 id="模型树"><a href="#模型树" class="headerlink" title="模型树"></a>模型树</h2><p>把叶节点设定成分段线性函数。<br>误差计算：先用模型拟合，然后计算真实目标与预测值之间的误差平方和。<br>在图像上表示由之前的线性回归变成了折线的线性回归。</p>
<h1 id="3-GBDT-梯度提升决策树"><a href="#3-GBDT-梯度提升决策树" class="headerlink" title="3. GBDT-梯度提升决策树"></a>3. GBDT-梯度提升决策树</h1><p>GBDT (Gradient Boosting Decision Tree) 又叫 MART （Multiple Additive Regression Tree)，是一种迭代的决策树算法，该算法由多棵决策树组成，所有树的结论累加起来做最终答案。它在被提出之初就和SVM一起被认为是泛化能力（generalization)较强的算法。近些年更因为被用于搜索排序的机器学习模型而引起大家关注。  </p>
<p>首先知道<strong>GBDT中的树都是回归树，不是分类树</strong>， GBDT的核心在于累加所有树的结果作为最终结果。</p>
<p>（<strong>GBM-gradient boosting machine</strong>）</p>
<p><strong>GBDT的思想使其天然可以发现多种有区分性的特征及特征组合<br>，所以工业界常用于LR的上一层模型，如Facebook的CTR预估</strong></p>
<h2 id="原理-4"><a href="#原理-4" class="headerlink" title="原理"></a>原理</h2><h3 id="Gradient-Boosting-梯度迭代"><a href="#Gradient-Boosting-梯度迭代" class="headerlink" title="Gradient Boosting-梯度迭代"></a>Gradient Boosting-梯度迭代</h3><p><strong>GBDT的核心就在于，每一棵树学的是之前所有树结论和的残差，这个残差就是一个加预测值后能得真实值的累加量</strong>。  </p>
<p><strong>选择特征</strong>：用<strong>CART TREE</strong>选择特征。先遍历训练样本的所有的特征，对于特征 j，我们遍历特征 j 所有特征值的切分点 c。找到可以让下面这个式子最小的特征 j 以及切分点c. </p>
<p><strong>残差</strong>： A的预测值 + A的残差 = A的实际值 </p>
<p><strong>Gradient</strong>：所以这里把前一棵树的预测结果的残差，给下一棵树训练，让z整体结果向全局最优的方向进行就是所谓的Gradient。（但并不是求导那种Gradient）</p>
<p><strong>损失函数</strong>：均方误差（回归）和LogLoss（分类）等。<br><img src="GBDT损失函数.png" alt="avatar"></p>
<p><strong>计算步长</strong>：用牛顿法计算步长，辅助shrinkage收缩步长防止过拟合。</p>
<p>计算结果：将所有树的结果*缩放因子 相加即预测结果。</p>
<p><strong>Boosting</strong>：每一步计算残差的过程也正是boosting对权重的修改。（虽然与AdaBoost不同）</p>
<pre><code>举例说明：A的真实年龄是18岁，但第一棵树的预测年龄是12岁，差了6岁，即残差为6岁。  
那么在第二棵树里我们把A的年龄设为6岁去学习，如果第二棵树真的能把A分到6岁的叶子节点，那累加两棵树的结论就是A的真实年龄；如果第二棵树的结论是5岁。
则A仍然存在1岁的残差，第三棵树里A的年龄就变成1岁，继续学。
</code></pre><h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><p><img src="GBDT算法流程.png" alt="avatar"></p>
<ol>
<li>rim为回归树m-1的负梯度，被当回归树m做残差的估计（也就是回归树m的yi）。</li>
<li>对rim捏合一棵回归树，回归树的叶子结点区域为Rmj，</li>
<li>线性搜索出来γjm使损失函数最小（也就是该区域对应取值，也就是落在该区域的样本本次迭代应该涨多少：γjm）</li>
<li>更新总体模型fm(x)（加和）</li>
</ol>
<h4 id="为什么要用负梯度作为残差的估计（最速下降方法）？？"><a href="#为什么要用负梯度作为残差的估计（最速下降方法）？？" class="headerlink" title="为什么要用负梯度作为残差的估计（最速下降方法）？？"></a>为什么要用负梯度作为残差的估计（最速下降方法）？？</h4><p>用泰勒一阶展开式可证明：（<strong>泰勒二阶展开式可以证明xgb梯度下降的原理</strong>）<br><img src="DBDT优化目标及负梯度理论.jpeg" alt="avatar"></p>
<h3 id="特点-3"><a href="#特点-3" class="headerlink" title="特点"></a>特点</h3><p>一般的回归树容易过拟合，只要叶子足够多，就能达到很高的训练数据准确度，但是泛化很差。  </p>
<pre><code>优点：  
并且GBDT通过梯度迭代的方式，需要了更少的特征。  
GBDT的适用范围非常广，几乎适用所有回归问题，还有二分类问题。  
不需要做特征归一，可以自动选择特征。

缺点：  
串行过程。  
计算复杂度高。  
不适用高维稀疏数据。
</code></pre><p>对弱分类器的要求比较简单，能达到低方差高偏差就行，因为迭代过程是针对偏差的。</p>
<p>相比<strong>RF关注树的数量</strong>，<strong>GBDT关注每棵树的深度</strong>（一般是1）。</p>
<h3 id="Shrinkage"><a href="#Shrinkage" class="headerlink" title="Shrinkage"></a>Shrinkage</h3><p>Shrinkage的思想是：类似于step。每次走一小步逐渐逼近结果的效果，要比每次迈一大步很快逼近结果的方式更容易<strong>避免过拟合</strong>。即它不完全信任每一个棵残差树，它认为每棵树只学到了真理的一小部分，累加的时候只累加一小部分，通过多学几棵树弥补不足。</p>
<p>也就是把每次计算出的残差拿出一部分给下一棵树学习，只累加一小部分。将陡变变成渐变。</p>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p>shrinkage（收缩步长）和采样比例可以理解为正则化的手段。</p>
<h3 id="用GBDT构造特征"><a href="#用GBDT构造特征" class="headerlink" title="用GBDT构造特征"></a>用GBDT构造特征</h3><p>建GBDT的多棵决策树，每个叶子节点可以理解为一维特征，落在该叶节点就是1，未落在就是0.再加上原来的特征一起输入到如LR中，可以有显著的效果提升。<br>相当于用GBDT的训练结果作为特征组合的方式。</p>
<h3 id="GBDT用于分类"><a href="#GBDT用于分类" class="headerlink" title="GBDT用于分类"></a>GBDT用于分类</h3><p><a href="https://zhuanlan.zhihu.com/p/25257856?refer=data-miner" target="_blank" rel="noopener">GBDT解决分类</a><br>解决回归问题的时候是计算残差得到最优，但是分类问题没办法计算残差，类别之间没办法比较。  </p>
<p>分类的时候损失函数使用<strong>log损失函数</strong>，评估最大化预测值为真实值的概率，为什么：参考了最大似然估计的计算原理。</p>
<p>有较多公式推导。</p>
<h2 id="搜索引擎排序应用-RankNet"><a href="#搜索引擎排序应用-RankNet" class="headerlink" title="搜索引擎排序应用 RankNet"></a>搜索引擎排序应用 RankNet</h2><h1 id="4-XGBoost"><a href="#4-XGBoost" class="headerlink" title="4. XGBoost"></a>4. XGBoost</h1><p><a href="https://blog.csdn.net/han_xiaoyang/article/details/52665396" target="_blank" rel="noopener">整体知识</a><br>Gradient Boosting的一种高效系统实现，不是一种单一算法，xgboost里面的基学习器除了用tree(gbtree)（这里相当于对GBDT的优化），也可用线性分类器(gblinear)。<br>传统GBDT以CART作为基分类器，xgboost还支持线性分类器，加了剪枝。</p>
<h2 id="原理-5"><a href="#原理-5" class="headerlink" title="原理"></a>原理</h2><h3 id="构造回归树"><a href="#构造回归树" class="headerlink" title="构造回归树"></a>构造回归树</h3><h4 id="（1）贪心算法"><a href="#（1）贪心算法" class="headerlink" title="（1）贪心算法"></a>（1）贪心算法</h4><p><img src="./贪婪算法.png" alt="avatar"></p>
<h4 id="（2）近似算法-加速-减小内存消耗"><a href="#（2）近似算法-加速-减小内存消耗" class="headerlink" title="（2）近似算法 - 加速+减小内存消耗"></a>（2）近似算法 - 加速+减小内存消耗</h4><p><img src="./近似算法.png" alt="avatar"></p>
<h3 id="特点-4"><a href="#特点-4" class="headerlink" title="特点"></a>特点</h3><ol>
<li>显示的把树模型复杂度作为<strong>正则项</strong>加到了<strong>目标函数</strong>中。</li>
<li>公式推导中用到了<strong>二阶导数</strong>，用了<strong>二阶泰勒展开</strong>。<ol start="3">
<li>展开点是上一个树的结果。对权重w求导，令导数为0。</li>
<li>在后面划分桶的时候，还将二阶导数h作为每个样本的权重。（代表划分通的间距）</li>
</ol>
</li>
<li>残差：划分前后的误差增益。</li>
<li><strong>并行化处理</strong>—系统设计模块,块结构设计等<ol start="7">
<li>xgboost还设计了高速缓存压缩感知算法</li>
<li>exact greedy algorithm采用缓存感知预取算法 </li>
<li>approximate algorithms选择合适的块大小</li>
</ol>
</li>
<li>CPU cache命中优化。</li>
<li>灵活，支持多种分类器，适用多种场景。</li>
<li><strong>行、列抽样</strong>。类似于RF的随机化处理，降低了反差（相关性），防止了过拟合。</li>
<li>Built-in Cross-Validation（内置交叉验证)</li>
<li>continue on Existing Model（接着已有模型学习）</li>
</ol>
<h3 id="创新点"><a href="#创新点" class="headerlink" title="创新点"></a>创新点</h3><ol>
<li><strong>pre-sorted算法</strong>：数据事先排序并且以<strong>block</strong>形式存储。（有利于并行计算）<ol start="2">
<li><strong>column block for parallel learning</strong>：预排序（减少建树时间）+block（减少排序时间），block的排序相当于是对每个特征，用他们的值来排序，每个值是一个指针，指向那条数据。这样每个特征可以分开排序，不用去存储整条数据。</li>
</ol>
</li>
<li><strong>exact greedy algorithm贪心算法</strong>（老版划分算法）：遍历所有特征及所有取值（<strong>已排序</strong>，两重循环），用分裂前后总loss（loss是当前这棵树所要拟合的loss）变化来做信息增益的计算。（非并行）</li>
<li><strong>approximate algorithm可并行的近似直方图算法</strong>（最明显提升的优化措施）：近似算法，根据特征的分布来（密集的分布区域采样多，稀疏的地方采样少）<strong>分成桶</strong>，把所有样本放入对应的桶，用桶来计算增益。减少了计算量。</li>
<li><strong>weighted quantile sketch</strong>：采样时，让候选点之间的距离不小于一个值。</li>
<li><strong>sparsity-aware splict finding缺失值处理，稀疏性利用</strong>：针对特征稀疏的情况，针对这种情况，让所有缺失值尝试所有进入左、右分裂方向，哪个增益大进入哪个。（进入一个分裂方向会一直走到头，再去试另一个方向）</li>
</ol>
<h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><h3 id="增加随机性"><a href="#增加随机性" class="headerlink" title="增加随机性"></a>增加随机性</h3><ul>
<li><strong>eta</strong> 这个就是学习速度，也就是上面中的ϵ。</li>
<li><strong>subsample</strong> 这个就是随机森林的方式，每次不是取出全部样本，而是有放回地取出部分样本。有人把这个称为行抽取，subsample就表示抽取比例。</li>
<li><strong>colsample_bytree</strong> 和<strong>colsample_bylevel</strong> 这个是模仿随机森林的方式，这是列抽取。colsample_bytree是每次准备构造一棵新树时，选取部分特征来构造，colsample_bytree就是抽取比例。colsample_bylevel表示的是每次分割节点时，抽取特征的比例。（列抽样-防止过拟合）</li>
<li><strong>max_delta_step</strong> 这个是构造树时，允许得到ft(x)的最大值。如果为0，表示无限制。就是每棵树权重改变的最大步长。</li>
</ul>
<h3 id="防止过拟合（正则化-剪枝）"><a href="#防止过拟合（正则化-剪枝）" class="headerlink" title="防止过拟合（正则化+剪枝）"></a>防止过拟合（正则化+剪枝）</h3><ul>
<li><strong>max_depth</strong> 树的最大深度（剪枝）</li>
<li><strong>min_child_weight</strong> 如果一个节点的权重和小于这玩意，那就不分了。（后剪枝？）</li>
<li><strong>gamma</strong> 指定了节点分裂所需的最小损失函数下降值。这个参数值越大，算法越保守。（后剪枝？）</li>
<li><strong>alpha</strong> 和<strong>lambda</strong> 就是目标函数里的表示模型复杂度中的L1范数和L2范数前面的系数。</li>
</ul>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><ul>
<li><strong>booster</strong> 表示用哪种模型，一共有gbtree, gbline, dart三种选择。一般用gbtree。</li>
<li><strong>nthread</strong> 并行线程数。如果不设置就是能采用的最大线程。</li>
<li><strong>sketch_eps</strong> 这个就是近似算法里的ϵ。</li>
<li><strong>scale_pos_weight</strong> 这个是针对二分类问题时，正负样例的数量差距过大。把这个参数设置为一个正数，可以使算法更快收敛。</li>
<li><strong>objective</strong> 定义需要被最小化的损失函数。默认[reg：linear]。还包括[binary：logistic]二分类的逻辑回归，返回概率而非类别。[multi:softmax]使用softmax的多分类器，返回预测的类别。</li>
</ul>
<h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3><ul>
<li>xgb的损失函数是什么，这个是可以自定义的，针对不同问题有各自适用的，如log、平方等</li>
<li><strong>xgb的目标函数</strong><ul>
<li><img src="./xgb目标函数.png" alt="avatar"></li>
<li><img src="./xgb目标函数正则项.png" alt="avatar"></li>
</ul>
</li>
</ul>
<h1 id="5-lightGBM"><a href="#5-lightGBM" class="headerlink" title="5. lightGBM"></a>5. lightGBM</h1><p><a href="https://blog.csdn.net/xwd18280820053/article/details/68927422" target="_blank" rel="noopener">多种树形分类器比较</a><br>首先GBDT的缺陷在于不能mini batch，效率太差，所以需要分布式的GBDT。</p>
<p>lightGBM使用了基于 histogram 的决策树算法。<br>xgboost（单机exact greedy算法/分布式dynamic histogram）选用了另一个主流决策树算法pre-sorted。</p>
<p>简单来说lgb比xgb的优点在于，使用histogram选择分割点的时候更加好，在构建决策树的计算过程有优化。</p>
<h3 id="histogram-VS-pre-sorted"><a href="#histogram-VS-pre-sorted" class="headerlink" title="histogram VS pre-sorted"></a>histogram VS pre-sorted</h3><ul>
<li>使用histogram算法（直方图算法）降低了训练数据在内存中的存储空间。</li>
<li>在构建决策树的时候，和pre-sorted算法一样需要O(data*feature)的时间复杂度来寻找分割点。但是histogram需要O(data)的时间复杂度来分割数据。pre-sorted需要O(data*feature)。因为他们的排序、索引方式不同。</li>
<li>histogram大幅减少了计算分割点增益的次数。计算分割点所有可能值的方式不同（也源于存储方式的不同）。</li>
<li>并行通信上histogram省去了大量的代价。这一点xgboost在并行通信上也是用histogram。</li>
<li>histogram不能精确的找到分割点，且训练误差没有pre-sorted优秀。（但是整体的模型效果上并不差或者会更好（可能粗分割可以带来正则化））</li>
<li>总的来说AUC和xgb差不多。</li>
<li>训练速度更快，收敛贼快。</li>
</ul>
<h3 id="创新点-1"><a href="#创新点-1" class="headerlink" title="创新点"></a>创新点</h3><ul>
<li><strong>GOSS：Gradient-based one-side sampling</strong>：完善增益定义。<ul>
<li>令数据按梯度排序，选topk大梯度的数据作为子集A，剩下的随机选部分作为子集B。（因为梯度大的数据更有用，减少了切分的时候的候选数量）</li>
<li>每次训练一个新树的时候选一次，相当于训练每棵树之前的抽样。</li>
</ul>
</li>
<li><strong>EFB：exclusive feature bundling</strong>：互斥特征绑定，合并成一个特征。（因为互斥不为0，针对稀疏的特征很好用）<ul>
<li>也对连续特征离散化。训练速度再次加强（相比xgb）。</li>
</ul>
</li>
</ul>
<h3 id="lightGBM的其他优化（VS-xgboost）"><a href="#lightGBM的其他优化（VS-xgboost）" class="headerlink" title="lightGBM的其他优化（VS xgboost）"></a>lightGBM的其他优化（VS xgboost）</h3><ul>
<li>不用大多数GBDT的按层生长，而用带有深度限制的按叶子生长 (leaf-wise) 算法。（level-wise容易多线程优化且不容易过拟合，但是效率过低。尽管leaf-wise容易树深度加深，过拟合，但是可以限制深度。且提高了效率。）</li>
<li>（并行方面）在直方图上也省去了冗余计算。</li>
</ul>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div></div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>打赏</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechatpay.jpg" alt="Hou Zhe 微信支付"/>
        <p>微信支付</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay.jpg" alt="Hou Zhe 支付宝"/>
        <p>支付宝</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    Hou Zhe
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="blog.lovelaolao.xin/机器学习/树形模型&XGBoost/" title="树形模型&XGBoost">blog.lovelaolao.xin/机器学习/树形模型&XGBoost/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/树模型/" rel="tag"><i class="fa fa-tag"></i> 树模型</a>
          
            <a href="/tags/XGB/" rel="tag"><i class="fa fa-tag"></i> XGB</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/机器学习/朴素贝叶斯/" rel="next" title="朴素贝叶斯">
                <i class="fa fa-chevron-left"></i> 朴素贝叶斯
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/实习面试经历/2018-暑期/2018-暑期实习总结/" rel="prev" title="2018-暑期实习面试总结">
                2018-暑期实习面试总结 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      
        <div onclick="showGitment()" id="gitment-display-button">显示 Gitment 评论</div>
        <div id="gitment-container" style="display:none"></div>
      
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/handsomeme.jpg"
                alt="Hou Zhe" />
            
              <p class="site-author-name" itemprop="name">Hou Zhe</p>
              <p class="site-description motion-element" itemprop="description">human learning, shallow leanring...</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">38</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">18</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">55</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/CC1993" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://weibo.com/u/3855613144" target="_blank" title="微博">
                      
                        <i class="fa fa-fw fa-weibo"></i>微博</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://leetcode.com/houser/" target="_blank" title="LeetCode">
                      
                        <i class="fa fa-fw fa-globe"></i>LeetCode</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                友情链接
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="http://blog.jiangdongyu.space/" title="酱小孩" target="_blank">酱小孩</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#0-Decision-Tree-决策树"><span class="nav-number">1.</span> <span class="nav-text">0. Decision Tree-决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#原理"><span class="nav-number">1.1.</span> <span class="nav-text">原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概念"><span class="nav-number">1.1.1.</span> <span class="nav-text">概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#工作原理"><span class="nav-number">1.1.2.</span> <span class="nav-text">工作原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#流程"><span class="nav-number">1.1.3.</span> <span class="nav-text">流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#树的纯度"><span class="nav-number">1.1.4.</span> <span class="nav-text">树的纯度</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#构建决策树的方法比较"><span class="nav-number">1.2.</span> <span class="nav-text">构建决策树的方法比较</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么多取值属性会包含更多的熵"><span class="nav-number">1.2.1.</span> <span class="nav-text">为什么多取值属性会包含更多的熵</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-随机森林-Radam-Forest-与-AdaBoost"><span class="nav-number">2.</span> <span class="nav-text">1. 随机森林-Radam Forest 与 AdaBoost</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#随机森林-bagging"><span class="nav-number">2.1.</span> <span class="nav-text">随机森林-bagging</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#原理-1"><span class="nav-number">2.1.1.</span> <span class="nav-text">原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#影响RF效果的参数"><span class="nav-number">2.1.2.</span> <span class="nav-text">影响RF效果的参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#流程-1"><span class="nav-number">2.1.3.</span> <span class="nav-text">流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特点"><span class="nav-number">2.1.4.</span> <span class="nav-text">特点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#AdaBoost-boosting"><span class="nav-number">2.2.</span> <span class="nav-text">AdaBoost-boosting</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#原理-2"><span class="nav-number">2.2.1.</span> <span class="nav-text">原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特点-1"><span class="nav-number">2.2.2.</span> <span class="nav-text">特点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#公式推导"><span class="nav-number">2.2.3.</span> <span class="nav-text">公式推导</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-回归树"><span class="nav-number">3.</span> <span class="nav-text">2. 回归树</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#原理-3"><span class="nav-number">3.0.1.</span> <span class="nav-text">原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#流程-2"><span class="nav-number">3.0.2.</span> <span class="nav-text">流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特点-2"><span class="nav-number">3.0.3.</span> <span class="nav-text">特点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#树剪枝-pruning"><span class="nav-number">3.1.</span> <span class="nav-text">树剪枝-pruning</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#预剪枝-prepruning"><span class="nav-number">3.1.1.</span> <span class="nav-text">预剪枝-prepruning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#后剪枝-postpruning"><span class="nav-number">3.1.2.</span> <span class="nav-text">后剪枝-postpruning</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#缺失值处理"><span class="nav-number">3.2.</span> <span class="nav-text">缺失值处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#多变量决策树"><span class="nav-number">3.3.</span> <span class="nav-text">多变量决策树</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型树"><span class="nav-number">3.4.</span> <span class="nav-text">模型树</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-GBDT-梯度提升决策树"><span class="nav-number">4.</span> <span class="nav-text">3. GBDT-梯度提升决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#原理-4"><span class="nav-number">4.1.</span> <span class="nav-text">原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Gradient-Boosting-梯度迭代"><span class="nav-number">4.1.1.</span> <span class="nav-text">Gradient Boosting-梯度迭代</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#算法流程"><span class="nav-number">4.1.2.</span> <span class="nav-text">算法流程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#为什么要用负梯度作为残差的估计（最速下降方法）？？"><span class="nav-number">4.1.2.1.</span> <span class="nav-text">为什么要用负梯度作为残差的估计（最速下降方法）？？</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特点-3"><span class="nav-number">4.1.3.</span> <span class="nav-text">特点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Shrinkage"><span class="nav-number">4.1.4.</span> <span class="nav-text">Shrinkage</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#正则化"><span class="nav-number">4.1.5.</span> <span class="nav-text">正则化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#用GBDT构造特征"><span class="nav-number">4.1.6.</span> <span class="nav-text">用GBDT构造特征</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GBDT用于分类"><span class="nav-number">4.1.7.</span> <span class="nav-text">GBDT用于分类</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#搜索引擎排序应用-RankNet"><span class="nav-number">4.2.</span> <span class="nav-text">搜索引擎排序应用 RankNet</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-XGBoost"><span class="nav-number">5.</span> <span class="nav-text">4. XGBoost</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#原理-5"><span class="nav-number">5.1.</span> <span class="nav-text">原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#构造回归树"><span class="nav-number">5.1.1.</span> <span class="nav-text">构造回归树</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#（1）贪心算法"><span class="nav-number">5.1.1.1.</span> <span class="nav-text">（1）贪心算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#（2）近似算法-加速-减小内存消耗"><span class="nav-number">5.1.1.2.</span> <span class="nav-text">（2）近似算法 - 加速+减小内存消耗</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#特点-4"><span class="nav-number">5.1.2.</span> <span class="nav-text">特点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创新点"><span class="nav-number">5.1.3.</span> <span class="nav-text">创新点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参数"><span class="nav-number">5.2.</span> <span class="nav-text">参数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#增加随机性"><span class="nav-number">5.2.1.</span> <span class="nav-text">增加随机性</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#防止过拟合（正则化-剪枝）"><span class="nav-number">5.2.2.</span> <span class="nav-text">防止过拟合（正则化+剪枝）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#其他"><span class="nav-number">5.2.3.</span> <span class="nav-text">其他</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#常见问题"><span class="nav-number">5.2.4.</span> <span class="nav-text">常见问题</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-lightGBM"><span class="nav-number">6.</span> <span class="nav-text">5. lightGBM</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#histogram-VS-pre-sorted"><span class="nav-number">6.0.1.</span> <span class="nav-text">histogram VS pre-sorted</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创新点-1"><span class="nav-number">6.0.2.</span> <span class="nav-text">创新点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#lightGBM的其他优化（VS-xgboost）"><span class="nav-number">6.0.3.</span> <span class="nav-text">lightGBM的其他优化（VS xgboost）</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2017 &mdash; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hou Zhe</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">112.4k</span>
  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      你是本站第
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      位访问者
    </span>
  

  
    <span class="site-pv">
      本站总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>





  <script type="text/javascript">
    (function() {
      var hm = document.createElement("script");
      hm.src = "//tajs.qq.com/stats?sId=65862436";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    
      <div id="needsharebutton-float">
        <span class="btn">
          <i class="fa fa-share-alt" aria-hidden="true"></i>
        </span>
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  







<!-- LOCAL: You can save these files to your site and update links -->
    
        
        <link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css">
        <script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script>
    
<!-- END LOCAL -->

    
      <style>
        a.gitment-editor-footer-tip { display: none; }
        .gitment-container.gitment-footer-container { display: none; }
      </style>
    

    
      <script type="text/javascript">
      function renderGitment(){
        var gitment = new Gitmint({
            id: window.location.pathname, 
            owner: 'CC1993',
            repo: 'CC1993.github.io',
            
            lang: "" || navigator.language || navigator.systemLanguage || navigator.userLanguage,
            
            oauth: {
            
            
                client_secret: 'dc6d091e130f79570e46d555eed19e556888eed4',
            
                client_id: '603f6e3d251801be8556'
            }});
        gitment.render('gitment-container');
      }

      
      function showGitment(){
        document.getElementById("gitment-display-button").style.display = "none";
        document.getElementById("gitment-container").style.display = "block";
        renderGitment();
      }
      
      </script>
    







  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("AQluv9b2gHsQHXCoEPbYTLVQ-gzGzoHsz", "qEL5EpDtAcgdujB3rqUpopWe");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
    
      flOptions = {};
      
          flOptions.iconStyle = "box";
      
          flOptions.boxForm = "horizontal";
      
          flOptions.position = "middleRight";
      
          flOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-float', flOptions);
    
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

  

  
  


  

  

</body>
</html>
